{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b361aa49-a247-4b15-8f83-2055f7ed22d6",
   "metadata": {},
   "source": [
    "# Practice exercises \\#7 with answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36605210-77ea-461d-90b2-69be81d71510",
   "metadata": {},
   "source": [
    "For the following exercises, you will use the text file with the Oliver Twist book, which you can download from https://gutenberg.org/cache/epub/730/pg730.txt and load it as a file.\n",
    "\n",
    "**Note:** For this set of exercises, you should remove all the punctuation prior to processing the text. To do this, you can use the following, where *text* is the variable where you want to remove the punctuation:\n",
    "\n",
    "```\n",
    "import string\n",
    "\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "text.translate(translator)\n",
    "```\n",
    "\n",
    "The following questions refer to the text of this book:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b6cf5c-1b16-4d7b-a4da-3451448c87d2",
   "metadata": {},
   "source": [
    "1. Count the number of words (of any length) that only contain letters within the a-g range in the alphabet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4da771e8-f1e5-4fc3-80f1-8da8fad1bba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4827 out of 161005 words match this criterion.\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def is_ag(word):\n",
    "    for letter in word:\n",
    "        if letter < 'a' or letter > 'g':\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "ccount = 0\n",
    "tcount = 0\n",
    "with open('files/pg730.txt', 'r') as fh:\n",
    "    for line in fh:\n",
    "        words = [w.translate(translator) for w in line.split()]\n",
    "        \n",
    "        for word in words:\n",
    "            tcount += 1\n",
    "            ccount += 1 if is_ag(word) else 0\n",
    "            \n",
    "print(ccount, 'out of', tcount, 'words match this criterion.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfd31bd-2a27-4c76-9781-50e008fb2373",
   "metadata": {},
   "source": [
    "2. What is the most frequent of all the words that match the above criterion of only using letters within the range a-g?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efe50b4b-674e-43a0-bc5e-15a822b3066d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most frequent a-g word is a with 3605 occurrences.\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def is_ag(word):\n",
    "    for letter in word:\n",
    "        if letter < 'a' or letter > 'g':\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "wordfreqs = {}\n",
    "with open('files/pg730.txt', 'r') as fh:\n",
    "    for line in fh:\n",
    "        words = [w.translate(translator) for w in line.split()]\n",
    "        \n",
    "        for word in words:\n",
    "            if is_ag(word):\n",
    "                wordfreqs[word] = 1 + wordfreqs.get(word, 0)\n",
    "\n",
    "topword = ''\n",
    "topfreq = 0\n",
    "for word, freq in wordfreqs.items():\n",
    "    if freq > topfreq:\n",
    "        topword = word\n",
    "        topfreq = freq\n",
    "    \n",
    "print('The most frequent a-g word is', topword, 'with', topfreq, 'occurrences.')\n",
    "\n",
    "# Alternatively also the following gets the key with max value: max(wordfreqs, key=wordfreqs.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c58a7bc-c8f0-48c8-96e0-09ccad96196b",
   "metadata": {},
   "source": [
    "3. How many lines of the book have at least a number in them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa82c800-7a50-4417-b36c-7f23eaf2f799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n"
     ]
    }
   ],
   "source": [
    "# Option 1:\n",
    "def has_numbers(text):\n",
    "    return any(letter.isdigit() for letter in text)\n",
    "\n",
    "havenumbers = 0\n",
    "with open('files/pg730.txt', 'r') as fh:\n",
    "    for line in fh:\n",
    "        havenumbers += 1 if has_numbers(line) else 0\n",
    "            \n",
    "print(havenumbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6e79046-2022-4ff0-bebb-3a26029c6922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n"
     ]
    }
   ],
   "source": [
    "# Option 2:\n",
    "def has_numbers(text):\n",
    "    for letter in text:\n",
    "        if letter.isdigit():\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "havenumbers = 0\n",
    "with open('files/pg730.txt', 'r') as fh:\n",
    "    for line in fh:\n",
    "        if has_numbers(line):\n",
    "            havenumbers += 1\n",
    "            \n",
    "print(havenumbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07adb85f-9f8d-4c1c-95e3-ffbacc5d771a",
   "metadata": {},
   "source": [
    "For the following exercise, you will use the text file with the Romeo and Juliet book (in addition to the Olivier Twist book which you've already downloaded). You can get the text of Romeo and Juliet from https://gutenberg.org/cache/epub/1513/pg1513.txt.\n",
    "\n",
    "4. With these two books, after lowercasing and stripping punctuation, identify the number of words that are used in both books, as well as the number of words that are exclusive to each book. You should count each word only once, regardless of its number of occurrences within a book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28407ec5-c851-42f6-9a41-4597f03b7b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common words: 2795\n",
      "Exclusive to OT: 11550\n",
      "Exclusive to R&J: 2141\n"
     ]
    }
   ],
   "source": [
    "# option 1: recommended\n",
    "otwords = []\n",
    "with open('files/pg730.txt', 'r') as fh:\n",
    "    for line in fh:\n",
    "        otwords.extend([w.translate(translator) for w in line.split()])\n",
    "        \n",
    "rjwords = []\n",
    "with open('files/pg1513.txt', 'r') as fh:\n",
    "    for line in fh:\n",
    "        rjwords.extend([w.translate(translator) for w in line.split()])\n",
    "\n",
    "commonwords = len(set(otwords) & set(rjwords))\n",
    "print('Common words: ' + str(commonwords))\n",
    "\n",
    "otexclusive = len(set(otwords) - set(rjwords))\n",
    "print('Exclusive to OT: ' + str(otexclusive))\n",
    "\n",
    "rjexclusive = len(set(rjwords) - set(otwords))\n",
    "print('Exclusive to R&J: ' + str(rjexclusive))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "691225ee-a8b6-42e4-807d-138ba6da0c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11550\n",
      "2141\n",
      "2795\n"
     ]
    }
   ],
   "source": [
    "# option 2: VERY SLOW AND INEFFICIENT, NOT RECOMMENDED, AS IT IS MUCH FASTER USING SETS AS ABOVE\n",
    "otwords = []\n",
    "with open('files/pg730.txt', 'r') as fh:\n",
    "    for line in fh:\n",
    "        otwords.extend([w.translate(translator) for w in line.split()])\n",
    "        \n",
    "rjwords = []\n",
    "with open('files/pg1513.txt', 'r') as fh:\n",
    "    for line in fh:\n",
    "        rjwords.extend([w.translate(translator) for w in line.split()])\n",
    "        \n",
    "onlyot = []\n",
    "for word in otwords:\n",
    "    if word not in rjwords and word not in onlyot:\n",
    "        onlyot.append(word)\n",
    "        \n",
    "print(len(onlyot))\n",
    "\n",
    "onlyrj = []\n",
    "for word in rjwords:\n",
    "    if word not in otwords and word not in onlyrj:\n",
    "        onlyrj.append(word)\n",
    "        \n",
    "print(len(onlyrj))\n",
    "\n",
    "common = []\n",
    "for word in rjwords:\n",
    "    if word in otwords and word not in common:\n",
    "        common.append(word)\n",
    "        \n",
    "print(len(common))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcd4d05-d745-413e-9a73-140acf1fe58b",
   "metadata": {},
   "source": [
    "For the following exercises, you will use a dataset comprising food hygiene ratings pertaining to over 600k businesses across the UK. This is a real dataset obtained from the UK's Food Standards Agency, where each business is rated with a score from 0 (urgent improvement necessary) to 5 (very good). The dataset is provided in json format, in a file called 'food-hygiene-ratings.json'. Each entry in the dataset contains a business which, in addition to the hygiene rating score, provides information on the business type, its address, its local authority, etc.\n",
    "\n",
    "The following questions 5 and 6 are to be answered by using this dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee52e91-a4e1-4066-ba01-2d00c3f5ee33",
   "metadata": {},
   "source": [
    "5. If we group businesses by their local authority area (the 'LocalAuthorityName' field), what is the area with lower average rating across all its businesses?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e76a6242-77aa-48d0-bc97-d2fa9cf0ad0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The local authority area with the lowest average rating is 'Waltham Forest' with an average rating of 3.874604847207587\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "arearatings = {}\n",
    "avgratings = {}\n",
    "with open('food-hygiene-ratings.json', 'r') as fh:\n",
    "    for line in fh:\n",
    "        business = json.loads(line)\n",
    "        \n",
    "        if business['RatingValue'].isnumeric() and not business['LocalAuthorityName'] in arearatings:\n",
    "            arearatings[business['LocalAuthorityName']] = []\n",
    "            avgratings[business['LocalAuthorityName']] = []\n",
    "        if business['RatingValue'].isnumeric():\n",
    "            arearatings[business['LocalAuthorityName']].append(int(business['RatingValue']))\n",
    "            \n",
    "for area, ratings in arearatings.items():\n",
    "    avgratings[area] = sum(ratings) / len(ratings)\n",
    "    \n",
    "minarea = min(avgratings, key=avgratings.get)\n",
    "\n",
    "print('The local authority area with the lowest average rating is \\'' + minarea + '\\' with an average rating of ' + str(avgratings[minarea]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba999ee9-ec1d-43a0-a1d1-ce30b03dd69c",
   "metadata": {},
   "source": [
    "6. The 'RatingDate' indicates the date in which the Food Standards Agency last inspected a business. Using the information in this field for all businesses, produce a ranking of the months where the Food Standards Agency conducts its inspection (ranked from most to least)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "990bdcd7-91fd-4c9f-8b9e-e56ae05a9f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03: 61960 inspections.\n",
      "02: 54813 inspections.\n",
      "06: 52720 inspections.\n",
      "05: 50352 inspections.\n",
      "07: 50268 inspections.\n",
      "01: 50238 inspections.\n",
      "11: 47918 inspections.\n",
      "10: 42278 inspections.\n",
      "04: 40843 inspections.\n",
      "09: 39172 inspections.\n",
      "08: 38151 inspections.\n",
      "12: 28710 inspections.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "months = {}\n",
    "with open('food-hygiene-ratings.json', 'r') as fh:\n",
    "    for line in fh:\n",
    "        business = json.loads(line)\n",
    "        \n",
    "        if isinstance(business['RatingDate'], str):\n",
    "            month = business['RatingDate'].split('-')[1]\n",
    "            months[month] = 1 + months.get(month, 0)\n",
    "\n",
    "months = {k: v for k, v in sorted(months.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "for month in months:\n",
    "    print(month + ': ' + str(months[month]) + ' inspections.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d6b0a9-cc25-4ffa-9e22-03cc0fdb41d9",
   "metadata": {},
   "source": [
    "7. We have been tasked with simply counting the number of lines in each of our books (Romeo and Juliet & Oliver Twist). We have written the following code. We are getting seamingly correct answers, but is there anything that we could have done better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc3c7d2a-975c-4790-99ca-b777bb76b838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines in Oliver Twist: 19188\n",
      "Lines in Romeo and Juliet: 5649\n"
     ]
    }
   ],
   "source": [
    "# Original\n",
    "content_ot = ''\n",
    "with open('files/pg730.txt', 'r') as fh:\n",
    "    for line in fh:\n",
    "        content_ot += line\n",
    "        \n",
    "content_rj = ''\n",
    "with open('files/pg1513.txt', 'r') as fh:\n",
    "    for line in fh:\n",
    "        content_rj += line\n",
    "        \n",
    "print('Lines in Oliver Twist:', len(content_ot.split('\\n')))\n",
    "\n",
    "print('Lines in Romeo and Juliet:', len(content_rj.split('\\n')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd94d7f1-d867-477d-8c8c-0e67a3373d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines in Oliver Twist: 19187\n",
      "Lines in Romeo and Juliet: 5648\n"
     ]
    }
   ],
   "source": [
    "# You may write your improved solution here\n",
    "lines_ot = 0\n",
    "with open('files/pg730.txt', 'r') as fh:\n",
    "    for line in fh:\n",
    "        lines_ot += 1\n",
    "        \n",
    "lines_rj = 0\n",
    "with open('files/pg1513.txt', 'r') as fh:\n",
    "    for line in fh:\n",
    "        lines_rj += 1\n",
    "        \n",
    "print('Lines in Oliver Twist:', lines_ot)\n",
    "\n",
    "print('Lines in Romeo and Juliet:', lines_rj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a6cba1-b679-4e75-87c8-907c14251bf9",
   "metadata": {},
   "source": [
    "**Explanation:** the solution was indeed correct, with just a marginal difference. Let's get to the problem first though.\n",
    "\n",
    "In the original code, we were storing the entire content of the files into variables, to then count how many lines we had. This causes two problems:\n",
    "* We are storing the whole content of the files into our computer's memory, when we are not interested in the content. When files are large, this will be problematic and we may run out of memory. As we are only interested in counting lines, there is no need to store the entire content.\n",
    "* Storing the content then means we need a further step of splitting the content by line using .split() to count how many lines we have. This is an unnecessary step of processing a long string, especially problematic if the files are very large and the strings become very lengthy and difficult to process.\n",
    "\n",
    "By simply adding +1 for every line we read, we get what we need, and we get rid of the content as soon as we read it, no need to store everything.\n",
    "\n",
    "**Clarification on the marginal difference:** this is because the first approach storing the content adds a line break at the end of the last row, therefore creating an empty line after it which adds to the count. This is a minor issue and the point of this exercise was to avoid storing all the content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4d00f1-d2c0-484a-954c-feb1ed83a837",
   "metadata": {},
   "source": [
    "8. We have been tasked with identifying, from both books, the lines where the word 'English' appears, and to count the total number of words in those lines. We have written the following code and we are getting seamingly correct answers, but is there anything we could have done better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9807bcbe-40da-45de-a5aa-356f41af214e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oliver Twist - Words in lines with the word 'English': 62\n",
      "Romeo and Juliet - Words in lines with the word 'English': 2\n"
     ]
    }
   ],
   "source": [
    "# Original\n",
    "content_ot = ''\n",
    "with open('files/pg730.txt', 'r') as fh:\n",
    "    for line in fh:\n",
    "        content_ot += line\n",
    "        \n",
    "content_rj = ''\n",
    "with open('files/pg1513.txt', 'r') as fh:\n",
    "    for line in fh:\n",
    "        content_rj += line\n",
    "        \n",
    "wordcount_ot = 0\n",
    "for line in content_ot.split('\\n'):\n",
    "    if 'English' in line:\n",
    "        wordcount_ot += len(line.split(' '))\n",
    "        \n",
    "wordcount_rj = 0\n",
    "for line in content_rj.split('\\n'):\n",
    "    if 'English' in line:\n",
    "        wordcount_rj += len(line.split(' '))\n",
    "        \n",
    "print('Oliver Twist - Words in lines with the word \\'English\\':', wordcount_ot)\n",
    "print('Romeo and Juliet - Words in lines with the word \\'English\\':', wordcount_rj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea548f9c-840e-4c27-8986-66df378bd026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oliver Twist - Words in lines with the word 'English': 62\n",
      "Romeo and Juliet - Words in lines with the word 'English': 2\n"
     ]
    }
   ],
   "source": [
    "# You may write your improved solution here\n",
    "wordcount_ot = 0\n",
    "with open('files/pg730.txt', 'r') as fh:\n",
    "    for line in fh:\n",
    "        if 'English' in line:\n",
    "            wordcount_ot += len(line.split(' '))\n",
    "        \n",
    "wordcount_rj = 0\n",
    "with open('files/pg1513.txt', 'r') as fh:\n",
    "    for line in fh:\n",
    "        if 'English' in line:\n",
    "            wordcount_rj += len(line.split(' '))\n",
    "    \n",
    "print('Oliver Twist - Words in lines with the word \\'English\\':', wordcount_ot)\n",
    "print('Romeo and Juliet - Words in lines with the word \\'English\\':', wordcount_rj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37f0399-dc62-4883-a549-074e9b23af2c",
   "metadata": {},
   "source": [
    "**Explanation:** the problem in this case is very similar to the previous one. We have stored the entire content of the books, to then checks which lines have the word 'English'. Instead, there was no need to store any content; as we read through the lines, we check if the line contains the word 'English' to do the necessary calculations, get rid of that line and continue with the remainder of the file.\n",
    "\n",
    "Our files are relatively small in this case, but if we need to reuse our code with files that are a few GB, then we'll likely run out of space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58a9b59-bd0a-491d-9866-56600e3457bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
